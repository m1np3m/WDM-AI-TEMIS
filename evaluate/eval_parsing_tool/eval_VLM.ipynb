{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "labels = json.load(open('C:\\\\Users\\\\PC\\\\CODE\\\\WDM-AI-TEMIS\\\\data-finetune\\\\final_data\\\\final.json', 'r', encoding='utf-8'))\n",
    "vlm_res = json.load(open('C:\\\\Users\\\\PC\\\\CODE\\\\WDM-AI-TEMIS\\\\data-finetune\\\\qwen_results_final_updated.json', 'r', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: LLM initialized with JSON mode.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"Lỗi: OPENAI_API_KEY không được tìm thấy.\")\n",
    "else:\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        model_kwargs={\n",
    "            \"response_format\": {\"type\": \"json_object\"}\n",
    "        }\n",
    "    )\n",
    "    print(\"DEBUG: LLM initialized with JSON mode.\")\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate_table_extraction(ground_truth: str, predict: str, llm_model = None, debug: bool = False) -> any: # Thay đổi kiểu trả về nếu cần\n",
    "   parser = JsonOutputParser()\n",
    "\n",
    "   prompt_template_str = \"\"\"\n",
    "   Evaluate the accuracy of a table extraction tool by comparing two markdown tables.\n",
    "\n",
    "   Consider the following criteria:\n",
    "   - **Content**: Ensure matches and events in GROUND TRUTH are accurately represented in PREDICT.\n",
    "   - **Formatting**: Check formatting consistency, including spacing and alignment.\n",
    "   - **Data Integrity**: Verify accurate data representation of dates, teams, scores, match titles, and attendance.\n",
    "   - **Order**: Confirm event sequence consistency.\n",
    "\n",
    "   # Steps\n",
    "\n",
    "   1. **Content Comparison**: Match rows and confirm data accuracy (team names, scores, etc.).\n",
    "   2. **Formatting Review**: Check column alignment and use of whitespace.\n",
    "   3. **Data Integrity Check**: Identify missing data or inconsistencies.\n",
    "   4. **Order Verification**: Ensure consistent event sequences.\n",
    "   5. **Assessment**: Note discrepancies and provide a score (0-1).\n",
    "\n",
    "   # Output Format\n",
    "\n",
    "   You must respond with a JSON object containing only a score field with a float value between 0 and 1.\n",
    "   For example:\n",
    "   {{\"score\": 0.85}}\n",
    "\n",
    "   ### GROUND TRUTH\n",
    "   {ground_truth}\n",
    "\n",
    "   ### PREDICT\n",
    "   {predict}\n",
    "\n",
    "   Remember: Your entire response must be a valid JSON object with only a \"score\" field containing a number between 0 and 1.\n",
    "   \"\"\"\n",
    "   prompt = PromptTemplate.from_template(template=prompt_template_str)\n",
    "\n",
    "   try:\n",
    "      chain = prompt | llm_model | parser\n",
    "      if debug:\n",
    "         print(\"DEBUG: Chain created successfully.\")\n",
    "\n",
    "      invocation_payload = {\n",
    "         \"ground_truth\": ground_truth,\n",
    "         \"predict\": predict\n",
    "      }\n",
    "      if debug:\n",
    "         print(f\"DEBUG: Invoking chain with payload (first 100 chars of each): \\nGround truth: {ground_truth[:100]}...\\nPredict: {predict[:100]}...\")\n",
    "\n",
    "      # Để kiểm tra riêng lẻ LLM (bỏ qua parser tạm thời):\n",
    "      # formatted_prompt = prompt.invoke(invocation_payload)\n",
    "      # print(f\"DEBUG: Formatted prompt sent to LLM:\\n{formatted_prompt.to_string()}\") # Hoặc .text tùy phiên bản\n",
    "      # llm_output = llm_model.invoke(formatted_prompt)\n",
    "      # print(f\"DEBUG: Raw output from LLM:\\n{llm_output}\")\n",
    "      # res = parser.parse(llm_output) # Parse thủ công nếu muốn kiểm tra parser\n",
    "\n",
    "      res = chain.invoke(invocation_payload)\n",
    "      if debug:\n",
    "         print(f\"DEBUG: Chain invocation successful. Result (res): {res}\")\n",
    "         print(f\"DEBUG: Type of res: {type(res)}\")\n",
    "      return res\n",
    "\n",
    "   except Exception as e:\n",
    "      if debug:   \n",
    "         print(f\"ERROR in evaluate_table_extraction: {e}\")\n",
    "         import traceback\n",
    "         traceback.print_exc() # In ra chi tiết lỗi và dòng gây lỗi\n",
    "      return \"\" # Hoặc None, hoặc một giá trị báo lỗi cụ thể\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [03:01<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 0.7815950920245403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total_score = 0\n",
    "for sample in tqdm(labels):\n",
    "    image_path = sample['image_path']\n",
    "    # search for the same image in vlm_res\n",
    "    vlm_res_sample = None\n",
    "    for vlm_sample in vlm_res:\n",
    "        if vlm_sample['image_path'] == image_path:\n",
    "            vlm_res_sample = vlm_sample\n",
    "    if vlm_res_sample is None:\n",
    "        print(f\"Image {image_path} not found in vlm_res\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # danh gia\n",
    "    ground_truth = sample['markdown_content']\n",
    "    predict = vlm_res_sample['markdown_content']\n",
    "    \n",
    "    score = evaluate_table_extraction(ground_truth, predict, llm_model=llm, debug=False)\n",
    "    total_score += score['score']\n",
    "    # break\n",
    "    \n",
    "print(f\"Total score: {total_score/len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 8/163 [00:40<22:14,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 24/163 [01:28<06:15,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 31/163 [02:06<18:06,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 35/163 [02:17<08:38,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 36/163 [02:20<07:23,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 37/163 [02:22<06:32,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 38/163 [02:24<05:59,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 39/163 [02:26<05:29,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 44/163 [02:40<05:14,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 47/163 [02:47<04:44,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 65/163 [03:40<04:46,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 66/163 [03:42<04:27,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 67/163 [04:03<13:02,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 92/163 [05:14<03:09,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 93/163 [05:17<02:56,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 96/163 [05:24<02:48,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 98/163 [05:30<02:48,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 102/163 [05:40<02:34,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 104/163 [06:04<08:03,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 122/163 [07:14<05:37,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 150/163 [08:35<00:35,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 151/163 [08:37<00:31,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [09:13<00:00,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 0.8375886524822699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from gemini import generate\n",
    "import time\n",
    "\n",
    "total_score = 0\n",
    "successful_evaluations = 0\n",
    "max_retries = 3  # Maximum number of retries for handling connection errors\n",
    "\n",
    "for sample in tqdm(labels):\n",
    "    image_path = sample['image_path']\n",
    "    # search for the same image in vlm_res\n",
    "    vlm_res_sample = None\n",
    "    for vlm_sample in vlm_res:\n",
    "        if vlm_sample['image_path'] == image_path:\n",
    "            vlm_res_sample = vlm_sample\n",
    "    if vlm_res_sample is None:\n",
    "        print(f\"Image {image_path} not found in vlm_res\")\n",
    "        continue\n",
    "    \n",
    "    # danh gia\n",
    "    ground_truth = sample['markdown_content']\n",
    "    predict = vlm_res_sample['markdown_content']\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            score = generate(ground_truth, predict)\n",
    "            total_score += score\n",
    "            successful_evaluations += 1\n",
    "            break  # Exit the retry loop if successful\n",
    "        except ConnectionResetError as e:\n",
    "            print(f\"Connection error: {e}. Retrying {retries + 1}/{max_retries}...\")\n",
    "            retries += 1\n",
    "            time.sleep(2)  # Wait for 2 seconds before retrying\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            break  # Exit the retry loop on unexpected errors\n",
    "\n",
    "if successful_evaluations > 0:\n",
    "    print(f\"Total score: {total_score/successful_evaluations}\")\n",
    "else:\n",
    "    print(\"No successful evaluations to calculate average score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
