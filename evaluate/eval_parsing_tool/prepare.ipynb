{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "res_folder = \"C:\\\\Users\\\\PC\\\\CODE\\\\WDM-AI-TEMIS\\\\data-finetune\\\\final_data\"\n",
    "json_res = os.path.join(res_folder, \"final.json\")\n",
    "docling_json = os.path.join(res_folder, \"docling_json.json\")\n",
    "image_folder = \"C:\\\\Users\\\\PC\\\\CODE\\\\WDM-AI-TEMIS\\\\data-finetune\\\\final_data\\\\extracted_images\"\n",
    "pdf_paths = \"C:\\\\Users\\\\PC\\\\CODE\\\\WDM-AI-TEMIS\\\\data-finetune\\\\pdf4tabel\"\n",
    "res = json.load(open(json_res, 'r', encoding='utf-8'))\n",
    "pymupdf_json = os.path.join(res_folder, \"pymupdf_json.json\")\n",
    "\n",
    "new_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def take_image(image_path):\n",
    "    image_path = os.path.join(image_folder, image_path)\n",
    "    image = Image.open(image_path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = take_image(res[0]['image_path'])\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# from docling.datamodel.base_models import InputFormat\n",
    "# from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n",
    "# from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "# def docling_md(source):\n",
    "#     # source = os.path.join(image_folder, res[0]['image_path'])\n",
    "#     converter = DocumentConverter()\n",
    "#     result = converter.convert(source)\n",
    "#     return result.document.export_to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, sample in enumerate(res):\n",
    "#     image_path = sample['image_path']\n",
    "#     image_path = os.path.join(image_folder, image_path)\n",
    "#     if os.path.exists(image_path):\n",
    "#         sample['docling_md'] = docling_md(image_path)\n",
    "#         res[idx]['docling_md'] = sample['docling_md']\n",
    "#     else:\n",
    "#         sample['docling_md'] = \"Cannot extract image\"\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PymuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cần cài đặt các thư viện nếu chưa có:\n",
    "# pip install python-Levenshtein scikit-learn numpy\n",
    "\n",
    "import Levenshtein\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# --- Các hàm tính độ tương đồng (Giữ nguyên) ---\n",
    "\n",
    "import re\n",
    "\n",
    "def normalize_markdown_for_comparison(md_string):\n",
    "    if not isinstance(md_string, str):\n",
    "        return \"\"\n",
    "    # 1. Thay thế <br> hoặc <br /> bằng một khoảng trắng (hoặc newline nếu bạn muốn giữ cấu trúc nhiều dòng trong ô)\n",
    "    #    Ở đây, tôi thay bằng khoảng trắng để các ô thành một dòng dài hơn.\n",
    "    processed_string = re.sub(r'<br\\s*/?>', ' ', md_string)\n",
    "\n",
    "    # 2. (Tùy chọn) Xử lý các ký tự đặc biệt. Ví dụ, nếu PyMuPDF loại bỏ ☑:\n",
    "    #    Nếu bạn muốn so sánh có phân biệt ☑, bạn cần tìm cách giữ nó trong PyMuPDF output (khó)\n",
    "    #    Hoặc, loại bỏ nó khỏi cả hai chuỗi để so sánh công bằng hơn (mất thông tin)\n",
    "    #    processed_string = processed_string.replace(\"☑\", \"\") # Ví dụ loại bỏ\n",
    "\n",
    "    # 3. Chuẩn hóa nhiều khoảng trắng thành một khoảng trắng\n",
    "    processed_string = re.sub(r'\\s+', ' ', processed_string)\n",
    "\n",
    "    # 4. Strip từng dòng và kết hợp lại (quan trọng sau các thay đổi)\n",
    "    lines = [line.strip() for line in processed_string.split('\\n') if line.strip()] # Lọc dòng trống\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def levenshtein_similarity(str1, str2):\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    if max_len == 0:\n",
    "        return 1.0\n",
    "    return 1.0 - (distance / max_len)\n",
    "\n",
    "def jaccard_similarity_lines(table1_str, table2_str):\n",
    "    \"\"\"\n",
    "    Tính độ tương đồng Jaccard dựa trên các dòng của hai bảng.\n",
    "    Đã cải thiện để robust hơn với khoảng trắng ở đầu/cuối dòng và các dòng trống.\n",
    "    \"\"\"\n",
    "    lines1 = {line.strip() for line in table1_str.strip().split('\\n') if line.strip()}\n",
    "    lines2 = {line.strip() for line in table2_str.strip().split('\\n') if line.strip()}\n",
    "\n",
    "    if not lines1 and not lines2:\n",
    "        return 1.0\n",
    "    if not lines1 or not lines2:\n",
    "        return 0.0\n",
    "\n",
    "    intersection = len(lines1.intersection(lines2))\n",
    "    union = len(lines1.union(lines2))\n",
    "\n",
    "    if union == 0: # Về lý thuyết không đạt tới đây nếu đã qua các check trên\n",
    "        return 1.0 \n",
    "    return intersection / union\n",
    "\n",
    "def calculate_cosine_similarity_for_list(table_list_to_compare, ground_truth_table):\n",
    "    if not table_list_to_compare:\n",
    "        return np.array([])\n",
    "\n",
    "    documents = [ground_truth_table] + table_list_to_compare\n",
    "\n",
    "    try:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    except ValueError:\n",
    "        similarities = []\n",
    "        for doc_str_in_list in table_list_to_compare:\n",
    "            gt_is_empty = not ground_truth_table.strip()\n",
    "            doc_is_empty = not doc_str_in_list.strip()\n",
    "            if gt_is_empty and doc_is_empty:\n",
    "                 similarities.append(1.0)\n",
    "            elif (gt_is_empty and not doc_is_empty) or (not gt_is_empty and doc_is_empty):\n",
    "                 similarities.append(0.0)\n",
    "            else:\n",
    "                 similarities.append(0.0)\n",
    "        return np.array(similarities)\n",
    "\n",
    "    if tfidf_matrix.shape[0] < 2 :\n",
    "        return np.zeros(len(table_list_to_compare))\n",
    "\n",
    "    ground_truth_vector = tfidf_matrix[0]\n",
    "    other_vectors = tfidf_matrix[1:]\n",
    "\n",
    "    if other_vectors.shape[0] == 0:\n",
    "        return np.zeros(len(table_list_to_compare))\n",
    "\n",
    "    similarities = cosine_similarity(ground_truth_vector, other_vectors)\n",
    "    return similarities.flatten()\n",
    "\n",
    "# --- Hàm Ensemble Chính (Cập nhật với Ngưỡng) ---\n",
    "\n",
    "def find_most_similar_table_ensemble(label_table_str, list_of_table_strs, verbose=True, min_similarity_threshold=None):\n",
    "    \"\"\"\n",
    "    Tìm chỉ số của bảng trong list_of_table_strs giống nhất với label_table_str\n",
    "    sử dụng phương pháp ensemble (trung bình) các điểm tương đồng.\n",
    "    Nếu không có bảng nào đạt ngưỡng tương đồng tối thiểu, trả về -1.\n",
    "\n",
    "    Args:\n",
    "        label_table_str (str): Chuỗi Markdown của bảng ground truth.\n",
    "        list_of_table_strs (list): Danh sách các chuỗi Markdown của các bảng cần so sánh.\n",
    "        verbose (bool): Nếu True, in ra các điểm tương đồng chi tiết.\n",
    "        min_similarity_threshold (float, optional): Ngưỡng tương đồng trung bình tối thiểu\n",
    "                                                     để một bảng được coi là khớp.\n",
    "                                                     Nếu None, không áp dụng ngưỡng (trả về chỉ số tốt nhất).\n",
    "                                                     Mặc định là None.\n",
    "\n",
    "    Returns:\n",
    "        int: Chỉ số của bảng giống nhất nếu đạt ngưỡng.\n",
    "             Trả về -1 nếu không có bảng nào đạt ngưỡng, danh sách rỗng, hoặc có lỗi.\n",
    "    \"\"\"\n",
    "    if not all(isinstance(s, str) for s in [label_table_str] + list_of_table_strs):\n",
    "        if verbose:\n",
    "            print(\"Lỗi: Không phải tất cả đầu vào đều là chuỗi. Hãy đảm bảo label và tất cả các bảng trong danh sách là chuỗi.\")\n",
    "        return -1\n",
    "\n",
    "    if not list_of_table_strs:\n",
    "        if verbose:\n",
    "            print(\"Danh sách bảng để so sánh trống.\")\n",
    "        return -1\n",
    "\n",
    "    num_tables = len(list_of_table_strs)\n",
    "    levenshtein_scores = np.zeros(num_tables)\n",
    "    jaccard_scores = np.zeros(num_tables)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"--- Levenshtein Similarity ---\")\n",
    "    for i, table_content in enumerate(list_of_table_strs):\n",
    "        sim = levenshtein_similarity(label_table_str, table_content)\n",
    "        levenshtein_scores[i] = sim\n",
    "        if verbose:\n",
    "            print(f\"Bảng {i} vs ground truth: {sim:.4f}\")\n",
    "    if num_tables > 0:\n",
    "        best_levenshtein_idx = np.argmax(levenshtein_scores)\n",
    "        if verbose:\n",
    "            print(f\"Chỉ số bảng giống nhất (Levenshtein): {best_levenshtein_idx} với điểm {levenshtein_scores[best_levenshtein_idx]:.4f}\\n\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"--- Jaccard Similarity (dựa trên các dòng) ---\")\n",
    "    for i, table_content in enumerate(list_of_table_strs):\n",
    "        sim = jaccard_similarity_lines(label_table_str, table_content)\n",
    "        jaccard_scores[i] = sim\n",
    "        if verbose:\n",
    "            print(f\"Bảng {i} vs ground truth: {sim:.4f}\")\n",
    "    if num_tables > 0:\n",
    "        best_jaccard_idx = np.argmax(jaccard_scores)\n",
    "        score_to_display_jaccard = jaccard_scores[best_jaccard_idx] if jaccard_scores.size > 0 else 0.0\n",
    "        if verbose:\n",
    "            print(f\"Chỉ số bảng giống nhất (Jaccard - dòng): {best_jaccard_idx} với điểm {score_to_display_jaccard:.4f}\\n\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"--- Cosine Similarity (TF-IDF) ---\")\n",
    "    cosine_scores = calculate_cosine_similarity_for_list(list_of_table_strs, label_table_str)\n",
    "    if cosine_scores.size == num_tables:\n",
    "        for i, score in enumerate(cosine_scores):\n",
    "            if verbose:\n",
    "                print(f\"Bảng {i} vs ground truth: {score:.4f}\")\n",
    "        best_cosine_idx = np.argmax(cosine_scores) if cosine_scores.size > 0 else 0\n",
    "        score_to_display_cosine = cosine_scores[best_cosine_idx] if cosine_scores.size > 0 else 0.0\n",
    "        if verbose:\n",
    "             print(f\"Chỉ số bảng giống nhất (Cosine TF-IDF): {best_cosine_idx} với điểm {score_to_display_cosine:.4f}\\n\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"Không thể tính toán Cosine scores một cách chính xác, sử dụng điểm 0 cho ensemble.\\n\")\n",
    "        cosine_scores = np.zeros(num_tables)\n",
    "\n",
    "    if not (len(levenshtein_scores) == num_tables and \\\n",
    "            len(jaccard_scores) == num_tables and \\\n",
    "            len(cosine_scores) == num_tables):\n",
    "        if verbose:\n",
    "            print(\"Lỗi: Kích thước của các mảng điểm không khớp để tính trung bình.\")\n",
    "        return -1\n",
    "\n",
    "    average_scores = (levenshtein_scores + jaccard_scores + cosine_scores) / 3.0\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"--- Điểm Trung Bình ---\")\n",
    "        for i, avg_score in enumerate(average_scores):\n",
    "            print(f\"Bảng {i} - Điểm trung bình: {avg_score:.4f}\")\n",
    "\n",
    "    if average_scores.size > 0:\n",
    "        best_average_idx = np.argmax(average_scores)\n",
    "        highest_avg_score = average_scores[best_average_idx]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nChỉ số bảng có điểm trung bình cao nhất: {best_average_idx} với điểm trung bình {highest_avg_score:.4f}\")\n",
    "            if min_similarity_threshold is not None:\n",
    "                 print(f\"Ngưỡng tương đồng tối thiểu yêu cầu: {min_similarity_threshold:.4f}\")\n",
    "\n",
    "        if min_similarity_threshold is not None:\n",
    "            if highest_avg_score >= min_similarity_threshold:\n",
    "                if verbose:\n",
    "                    print(f\"Điểm trung bình cao nhất ({highest_avg_score:.4f}) >= ngưỡng ({min_similarity_threshold:.4f}). Trả về chỉ số.\")\n",
    "                return int(best_average_idx)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"Điểm trung bình cao nhất ({highest_avg_score:.4f}) < ngưỡng ({min_similarity_threshold:.4f}). Không có bảng nào đủ giống. Trả về -1.\")\n",
    "                return -1\n",
    "        else: # Không có ngưỡng, trả về chỉ số tốt nhất\n",
    "            if verbose:\n",
    "                print(\"Không có ngưỡng tương đồng tối thiểu nào được áp dụng. Trả về chỉ số tốt nhất.\")\n",
    "            return int(best_average_idx)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"\\nKhông thể tính điểm trung bình tổng hợp hoặc không có bảng nào để đánh giá.\")\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from markdown import markdown\n",
    "import pandas as pd\n",
    "\n",
    "def convert_markdown_to_df(markdown_text: str) -> pd.DataFrame:\n",
    "    html_table = markdown(markdown_text, extensions=[\"markdown.extensions.tables\"])\n",
    "    dfs = pd.read_html(StringIO(f\"<table>{html_table}</table>\"))\n",
    "    if dfs:\n",
    "        df = dfs[0]\n",
    "    else:\n",
    "        print(\"Không tìm thấy bảng nào.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def fix_merged_row(df_col1, df_col2) -> pd.Series:\n",
    "    def find_consecutive_true_indices(series):\n",
    "        consecutive_groups = []\n",
    "        current_streak = []\n",
    "\n",
    "        for i, value in enumerate(series):\n",
    "            if value:\n",
    "                current_streak.append(i)\n",
    "            else:\n",
    "                if len(current_streak) >= 2:\n",
    "                    consecutive_groups.append(current_streak)\n",
    "                current_streak = []\n",
    "\n",
    "        if len(current_streak) >= 2:\n",
    "            consecutive_groups.append(current_streak)\n",
    "\n",
    "        return consecutive_groups\n",
    "\n",
    "    consecutive_true_indices = find_consecutive_true_indices(df_col1 == df_col2)\n",
    "    if consecutive_true_indices:\n",
    "        for group in consecutive_true_indices:\n",
    "            if group and len(group) > 1 and group[0] - 1 >= 0:\n",
    "                replace_value = df_col2.iloc[group[0] - 1]\n",
    "                df_col2.iloc[group] = replace_value\n",
    "    return df_col2\n",
    "\n",
    "\n",
    "def fix_merged_row_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    test_df = df.copy()\n",
    "\n",
    "    n_cols = test_df.shape[1]\n",
    "    processed_cols = []\n",
    "    for i in range(1, n_cols - 1):\n",
    "        col1 = test_df.iloc[:, i]\n",
    "        col2 = test_df.iloc[:, i + 1]\n",
    "        processed_cols.append(fix_merged_row(col1, col2))\n",
    "\n",
    "    for i in range(2, n_cols):\n",
    "        test_df.iloc[:, i] = processed_cols[i - 2]\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "\n",
    "def get_pdf_name(source: str) -> str:\n",
    "    pdf_name = os.path.basename(source)\n",
    "    file_name_part, file_extension_part = os.path.splitext(pdf_name)\n",
    "    return file_name_part\n",
    "\n",
    "def pymupdf_md(sample): \n",
    "    pdf_name = get_pdf_name(sample['source_pdf'])\n",
    "    source_pdf_path = os.path.join(pdf_paths, pdf_name+\".pdf\")\n",
    "\n",
    "    doc = pymupdf.open(source_pdf_path)\n",
    "    extracted_raw_markdown_tables = []\n",
    "    for page_num, page in enumerate(doc): # Thêm page_num để debug nếu cần\n",
    "        try:\n",
    "            # Cân nhắc các strategy khác nhau: \"lines\", \"lines_strict\", \"text\"\n",
    "            # find_tables() trả về một TableFinder object\n",
    "            table_finder = page.find_tables(strategy=\"lines_strict\") \n",
    "            if table_finder.tables: # Kiểm tra xem có bảng nào được tìm thấy không\n",
    "                for table in table_finder.tables:\n",
    "                    extracted_raw_markdown_tables.append(table.to_markdown(clean=False)) # Thử nghiệm clean=False/True\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi trích xuất bảng từ trang {page_num} của file {sample['source_pdf']}: {e}\")\n",
    "    doc.close()\n",
    "\n",
    "    label_ground_truth = sample['markdown_content']\n",
    "    normalized_label = normalize_markdown_for_comparison(label_ground_truth)\n",
    "\n",
    "    # Chuẩn hóa các bảng đã trích xuất\n",
    "    normalized_extracted_tables = [normalize_markdown_for_comparison(t) for t in extracted_raw_markdown_tables]\n",
    "\n",
    "    # Lọc bỏ các chuỗi rỗng sau khi chuẩn hóa (nếu có)\n",
    "    # và giữ index gốc để tham chiếu lại bảng gốc nếu cần\n",
    "    valid_normalized_tables_with_original_indices = []\n",
    "    for i, norm_table in enumerate(normalized_extracted_tables):\n",
    "        if norm_table: # Chỉ xem xét các bảng không rỗng sau chuẩn hóa\n",
    "            valid_normalized_tables_with_original_indices.append((norm_table, i))\n",
    "\n",
    "    final_normalized_tables_to_compare = [item[0] for item in valid_normalized_tables_with_original_indices]\n",
    "\n",
    "\n",
    "    if not final_normalized_tables_to_compare:\n",
    "        # print(f\"Không có bảng nào hợp lệ được trích xuất từ {sample['source_pdf']} sau chuẩn hóa.\")\n",
    "        sample['pymupdf_md'] = \"No valid tables extracted or normalized\"\n",
    "        return sample\n",
    "\n",
    "    # Gọi hàm ensemble với dữ liệu đã chuẩn hóa\n",
    "    best_match_normalized_idx = find_most_similar_table_ensemble(\n",
    "        normalized_label, \n",
    "        final_normalized_tables_to_compare, # Danh sách các bảng đã chuẩn hóa\n",
    "        verbose=False, # Đặt True để debug nếu cần\n",
    "        min_similarity_threshold=0.3 \n",
    "    )\n",
    "\n",
    "    if best_match_normalized_idx != -1:\n",
    "        # Lấy index của bảng gốc từ PyMuPDF output\n",
    "        original_table_index = valid_normalized_tables_with_original_indices[best_match_normalized_idx][1]\n",
    "        table_selected_original_format = extracted_raw_markdown_tables[original_table_index]\n",
    "        \n",
    "        df = convert_markdown_to_df(table_selected_original_format)\n",
    "        df = fix_merged_row_df(df).copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "        \n",
    "        table_selected_original_format = df.to_markdown(index=False)\n",
    "        sample['pymupdf_md'] = table_selected_original_format\n",
    "    else:\n",
    "        sample['pymupdf_md'] = \"No suitable table found meeting threshold\"\n",
    "\n",
    "    return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/163 [00:13<37:27, 13.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm(res, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(res)):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mpymupdf_md\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m, in \u001b[0;36mpymupdf_md\u001b[1;34m(sample)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_num, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc): \u001b[38;5;66;03m# Thêm page_num để debug nếu cần\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;66;03m# Cân nhắc các strategy khác nhau: \"lines\", \"lines_strict\", \"text\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# find_tables() trả về một TableFinder object\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m         table_finder \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlines_strict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m table_finder\u001b[38;5;241m.\u001b[39mtables: \u001b[38;5;66;03m# Kiểm tra xem có bảng nào được tìm thấy không\u001b[39;00m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m table_finder\u001b[38;5;241m.\u001b[39mtables:\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\table.py:2427\u001b[0m, in \u001b[0;36mfind_tables\u001b[1;34m(page, clip, vertical_strategy, horizontal_strategy, vertical_lines, horizontal_lines, snap_tolerance, snap_x_tolerance, snap_y_tolerance, join_tolerance, join_x_tolerance, join_y_tolerance, edge_min_length, min_words_vertical, min_words_horizontal, intersection_tolerance, intersection_x_tolerance, intersection_y_tolerance, text_tolerance, text_x_tolerance, text_y_tolerance, strategy, add_lines, add_boxes, paths)\u001b[0m\n\u001b[0;32m   2424\u001b[0m page\u001b[38;5;241m.\u001b[39mtable_settings \u001b[38;5;241m=\u001b[39m tset\n\u001b[0;32m   2426\u001b[0m make_chars(page, clip\u001b[38;5;241m=\u001b[39mclip)  \u001b[38;5;66;03m# create character list of page\u001b[39;00m\n\u001b[1;32m-> 2427\u001b[0m \u001b[43mmake_edges\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2432\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2433\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_boxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2434\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# create lines and curves\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m tables \u001b[38;5;241m=\u001b[39m TableFinder(page, settings\u001b[38;5;241m=\u001b[39mtset)\n\u001b[0;32m   2437\u001b[0m TOOLS\u001b[38;5;241m.\u001b[39mset_small_glyph_heights(old_small)\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\table.py:2101\u001b[0m, in \u001b[0;36mmake_edges\u001b[1;34m(page, clip, tset, paths, add_lines, add_boxes)\u001b[0m\n\u001b[0;32m   2097\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m prects[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# remove from rect list\u001b[39;00m\n\u001b[0;32m   2099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_rects, paths\n\u001b[1;32m-> 2101\u001b[0m bboxes, paths \u001b[38;5;241m=\u001b[39m \u001b[43mclean_graphics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpaths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_parallel\u001b[39m(p1, p2):\n\u001b[0;32m   2104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if line is roughly axis-parallel.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\table.py:2094\u001b[0m, in \u001b[0;36mmake_edges.<locals>.clean_graphics\u001b[1;34m(npaths)\u001b[0m\n\u001b[0;32m   2091\u001b[0m             repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# keep checking the rest\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# move rect 0 over to result list if there is some text in it\u001b[39;00m\n\u001b[1;32m-> 2094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m white_spaces\u001b[38;5;241m.\u001b[39missuperset(\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_textbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprect0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtextpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEXTPAGE\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m   2095\u001b[0m     \u001b[38;5;66;03m# contains text, so accept it as a table bbox candidate\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m     new_rects\u001b[38;5;241m.\u001b[39mappend(prect0)\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m prects[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# remove from rect list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\utils.py:718\u001b[0m, in \u001b[0;36mget_textbox\u001b[1;34m(page, rect, textpage)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(tp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparent\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m page:\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot a textpage of this page\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 718\u001b[0m rc \u001b[38;5;241m=\u001b[39m \u001b[43mtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractTextbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m textpage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m tp\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\__init__.py:12805\u001b[0m, in \u001b[0;36mTextPage.extractTextbox\u001b[1;34m(self, rect)\u001b[0m\n\u001b[0;32m  12803\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(this_tpage, mupdf\u001b[38;5;241m.\u001b[39mFzStextPage)\n\u001b[0;32m  12804\u001b[0m area \u001b[38;5;241m=\u001b[39m JM_rect_from_py(rect)\n\u001b[1;32m> 12805\u001b[0m found \u001b[38;5;241m=\u001b[39m \u001b[43mJM_copy_rectangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis_tpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  12806\u001b[0m rc \u001b[38;5;241m=\u001b[39m PyUnicode_DecodeRawUnicodeEscape(found)\n\u001b[0;32m  12807\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rc\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\__init__.py:15000\u001b[0m, in \u001b[0;36mJM_copy_rectangle\u001b[1;34m(page, area)\u001b[0m\n\u001b[0;32m  14998\u001b[0m line_had_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m  14999\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m line:\n\u001b[1;32m> 15000\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mJM_char_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  15001\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m JM_rects_overlap(area, r):\n\u001b[0;32m  15002\u001b[0m         line_had_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\__init__.py:14725\u001b[0m, in \u001b[0;36mJM_char_bbox\u001b[1;34m(line, ch)\u001b[0m\n\u001b[0;32m  14721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mJM_char_bbox\u001b[39m(line, ch):\n\u001b[0;32m  14722\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m  14723\u001b[0m \u001b[38;5;124;03m    return rect of char quad\u001b[39;00m\n\u001b[0;32m  14724\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m> 14725\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[43mJM_char_quad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  14726\u001b[0m     r \u001b[38;5;241m=\u001b[39m mupdf\u001b[38;5;241m.\u001b[39mfz_rect_from_quad(q)\n\u001b[0;32m  14727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mm_internal\u001b[38;5;241m.\u001b[39mwmode:\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\__init__.py:14752\u001b[0m, in \u001b[0;36mJM_char_quad\u001b[1;34m(line, ch)\u001b[0m\n\u001b[0;32m  14746\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m  14747\u001b[0m \u001b[38;5;124;03mre-compute char quad if ascender/descender values make no sense\u001b[39;00m\n\u001b[0;32m  14748\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m  14749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m g_use_extra:\n\u001b[0;32m  14750\u001b[0m     \u001b[38;5;66;03m# This reduces time taken to extract text from PyMuPDF.pdf from 20s to\u001b[39;00m\n\u001b[0;32m  14751\u001b[0m     \u001b[38;5;66;03m# 15s.\u001b[39;00m\n\u001b[1;32m> 14752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mupdf\u001b[38;5;241m.\u001b[39mFzQuad(\u001b[43mextra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJM_char_quad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm_internal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm_internal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m  14754\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(line, mupdf\u001b[38;5;241m.\u001b[39mFzStextLine)\n\u001b[0;32m  14755\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ch, mupdf\u001b[38;5;241m.\u001b[39mFzStextChar)\n",
      "File \u001b[1;32mc:\\Users\\PC\\CODE\\WDM-AI-TEMIS\\.venv\\lib\\site-packages\\pymupdf\\extra.py:162\u001b[0m, in \u001b[0;36mJM_char_quad\u001b[1;34m(line, ch)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mJM_char_quad\u001b[39m(line, ch):\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJM_char_quad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Process samples sequentially with progress bar\n",
    "results = []\n",
    "for sample in tqdm(res, total=len(res)):\n",
    "    try:\n",
    "        result = pymupdf_md(sample)\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sample: {e}\")\n",
    "        results.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save json\n",
    "pymupdf_json = os.path.join(res_folder, \"pymupdf_json_2.json\")\n",
    "with open(pymupdf_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(res, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
