{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51d1ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install graphiti-core langchain-openai langgraph ipywidgets PyMuPDF qdrant-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee402e",
   "metadata": {},
   "source": [
    "Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7479d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Data\\WDM-AI-TEMIS\n",
      "c:/Users/Admin/Data/WDM-AI-TEMIS\n",
      "root_dir: c:/Users/Admin/Data/WDM-AI-TEMIS\n",
      "c:/Users/Admin/Data/WDM-AI-TEMIS/data\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/..')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "from configs.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b39032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Annotated\n",
    "import fitz  # PyMuPDF\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, PointStruct\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from graphiti_core import Graphiti\n",
    "from graphiti_core.edges import EntityEdge\n",
    "from graphiti_core.nodes import EpisodeType\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45efe1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "NEO4J_URI=os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME=os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD=os.getenv(\"NEO4J_PASSWORD\")\n",
    "QDRANT_URL=os.getenv(\"QDRANT_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689167f",
   "metadata": {},
   "source": [
    "Step 2: Verify Neo4j and Qdrant Connections\n",
    "\n",
    "Ensure Neo4j and Qdrant are running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11045009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j connected successfully\n",
      "Qdrant connected successfully\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Neo4j connection\n",
    "neo4j_driver = GraphDatabase.driver(\n",
    "    NEO4J_URI,\n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    ")\n",
    "with neo4j_driver.session() as session:\n",
    "    result = session.run(\"RETURN 1\")\n",
    "    assert result.single()[0] == 1, \"Neo4j connection failed\"\n",
    "print(\"Neo4j connected successfully\")\n",
    "\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "   path=f\"{exps_dir}/qdrant_client_memory\",\n",
    ")\n",
    "qdrant_client.get_collections()\n",
    "print(\"Qdrant connected successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f79ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name='graphrag_docs',\n",
    "    vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9abffc",
   "metadata": {},
   "source": [
    "Step 3: Data Ingestion\n",
    "\n",
    "Load Sample Data\n",
    "\n",
    "Use Wikipedia articles about \"Vietnam\" as the dataset. Replace with your own data as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# Load Wikipedia data\n",
    "raw_documents = WikipediaLoader(query=\"Vietnam\").load()\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(raw_documents[:3])\n",
    "print(f\"Loaded {len(documents)} document chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e785a2",
   "metadata": {},
   "source": [
    "Create Knowledge Graph with Graphiti\n",
    "\n",
    "Use Graphiti to extract entities and relationships and store them in Neo4j. Graphiti simplifies graph construction with episodic and relational data management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphiti_core import Graphiti\n",
    "from graphiti_core.nodes import Episode\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Initialize Graphiti\n",
    "graphiti = Graphiti(\n",
    "    uri=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Ingest documents as episodes\n",
    "for idx, doc in enumerate(documents):\n",
    "    episode = Episode(\n",
    "        name=f\"Vietnam_Doc_{idx}\",\n",
    "        content=doc.page_content,\n",
    "        source=\"Wikipedia\",\n",
    "        metadata=doc.metadata\n",
    "    )\n",
    "    graphiti.add_episode(episode)\n",
    "print(\"Knowledge graph created with Graphiti in Neo4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize embeddings\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create Qdrant collection\n",
    "collection_name = \"vietnam\"\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "# Initialize Qdrant vector store\n",
    "qdrant = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedder\n",
    ")\n",
    "\n",
    "# Add documents to Qdrant\n",
    "qdrant.add_documents(documents)\n",
    "print(f\"Stored {len(documents)} document embeddings in Qdrant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4215ee7",
   "metadata": {},
   "source": [
    "Step 4: Parallel Hybrid Retrieval\n",
    "\n",
    "Implement Parallel Retrieval\n",
    "\n",
    "Create a custom retriever that runs Qdrant vector search and Graphiti-based Neo4j graph search in parallel using Pythonâ€™s asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4af79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain_core.documents import Document\n",
    "from neo4j_graphrag.retrievers import QdrantNeo4jRetriever\n",
    "\n",
    "# Custom parallel retriever\n",
    "class ParallelHybridRetriever:\n",
    "    def __init__(self, qdrant_client, neo4j_driver, collection_name, embedder, graphiti):\n",
    "        self.qdrant_retriever = QdrantNeo4jRetriever(\n",
    "            driver=neo4j_driver,\n",
    "            client=qdrant_client,\n",
    "            collection_name=collection_name,\n",
    "            id_property_external=\"neo4j_id\",\n",
    "            id_property_neo4j=\"id\",\n",
    "            embedder=embedder\n",
    "        )\n",
    "        self.graphiti = graphiti\n",
    "        self.embedder = embedder\n",
    "\n",
    "    async def qdrant_search(self, query, top_k):\n",
    "        results = self.qdrant_retriever.search(query_text=query, top_k=top_k)\n",
    "        return [{\"text\": res.node.properties.get(\"text\", \"\"), \"score\": res.score} for res in results]\n",
    "\n",
    "    async def graphiti_search(self, query, top_k):\n",
    "        results = await self.graphiti.search(query=query, k=top_k)\n",
    "        return [{\"text\": res.node.content, \"score\": res.score} for res in results]\n",
    "\n",
    "    async def search(self, query, top_k=2):\n",
    "        # Run Qdrant and Graphiti searches in parallel\n",
    "        qdrant_task = self.qdrant_search(query, top_k)\n",
    "        graphiti_task = self.graphiti_search(query, top_k)\n",
    "        qdrant_results, graphiti_results = await asyncio.gather(qdrant_task, graphiti_task)\n",
    "\n",
    "        # Merge results (simple union with deduplication by text)\n",
    "        merged_results = []\n",
    "        seen_texts = set()\n",
    "        for res in qdrant_results + graphiti_results:\n",
    "            if res[\"text\"] not in seen_texts:\n",
    "                merged_results.append(res)\n",
    "                seen_texts.add(res[\"text\"])\n",
    "        return merged_results[:top_k]\n",
    "\n",
    "# Initialize retriever\n",
    "retriever = ParallelHybridRetriever(\n",
    "    qdrant_client=qdrant_client,\n",
    "    neo4j_driver=neo4j_driver,\n",
    "    collection_name=collection_name,\n",
    "    embedder=embedder,\n",
    "    graphiti=graphiti\n",
    ")\n",
    "\n",
    "# Test parallel retrieval\n",
    "async def test_retrieval():\n",
    "    query = \"What is the history of Vietnam's independence?\"\n",
    "    results = await retriever.search(query, top_k=2)\n",
    "    for res in results:\n",
    "        print(f\"Text: {res['text'][:100]}..., Score: {res['score']}\")\n",
    "\n",
    "# Run test\n",
    "await test_retrieval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73384ea0",
   "metadata": {},
   "source": [
    "Step 5: Set Up GraphQL API\n",
    "\n",
    "Define GraphQL Schema\n",
    "\n",
    "Create a GraphQL schema to query the hybrid retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f37b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ariadne import QueryType, gql, make_executable_schema\n",
    "from ariadne.asgi import GraphQL\n",
    "\n",
    "# Define GraphQL schema\n",
    "type_defs = gql(\"\"\"\n",
    "    type Query {\n",
    "        search(query: String!, top_k: Int!): [Result!]!\n",
    "    }\n",
    "\n",
    "    type Result {\n",
    "        text: String!\n",
    "        score: Float!\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "# Define resolvers\n",
    "query = QueryType()\n",
    "\n",
    "@query.field(\"search\")\n",
    "async def resolve_search(_, info, query, top_k):\n",
    "    results = await retriever.search(query, top_k)\n",
    "    return [{\"text\": res[\"text\"], \"score\": res[\"score\"]} for res in results]\n",
    "\n",
    "# Create executable schema\n",
    "schema = make_executable_schema(type_defs, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from ariadne.asgi.handlers import GraphQLHTTPHandler\n",
    "\n",
    "app = FastAPI()\n",
    "app.mount(\"/graphql\", GraphQL(schema, debug=True))\n",
    "\n",
    "# Run the server (execute in terminal: uvicorn script:app --host 0.0.0.0 --port 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548eb64",
   "metadata": {},
   "source": [
    "query {\n",
    "  search(query: \"What is the history of Vietnam's independence?\", top_k: 2) {\n",
    "    text\n",
    "    score\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear Neo4j database\n",
    "with neo4j_driver.session() as session:\n",
    "    session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "print(\"Neo4j database cleared\")\n",
    "\n",
    "# Delete Qdrant collection\n",
    "qdrant_client.delete_collection(collection_name)\n",
    "print(f\"Qdrant collection {collection_name} deleted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
