# -*- coding: utf-8 -*-
"""
HybriRAG v2 - Script Ch·∫°y Pipeline RAG Lai Gh√©p Vector v√† ƒê·ªì Th·ªã.

M√¥ t·∫£:
    Script n√†y tri·ªÉn khai m·ªôt h·ªá th·ªëng RAG (Retrieval-Augmented Generation) lai gh√©p,
    k·∫øt h·ª£p s·ª©c m·∫°nh c·ªßa c·∫£ c∆° s·ªü d·ªØ li·ªáu vector (ChromaDB) v√† c∆° s·ªü d·ªØ li·ªáu
    ƒë·ªì th·ªã (Neo4j) ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi ph·ª©c t·∫°p.

    Quy tr√¨nh ho·∫°t ƒë·ªông ch√≠nh:
    1.  **Ph√¢n r√£ c√¢u h·ªèi (Query Transformation)**: M·ªôt LLM ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√¢n t√≠ch
        c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng, t√°ch n√≥ th√†nh c√°c c√¢u h·ªèi con h∆∞·ªõng ƒë·∫øn t√¨m ki·∫øm
        vector (d·ªØ li·ªáu m√¥ t·∫£) v√† c√°c th·ª±c th·ªÉ ch√≠nh h∆∞·ªõng ƒë·∫øn t√¨m ki·∫øm ƒë·ªì th·ªã
        (d·ªØ li·ªáu th·ª±c t·∫ø, c√≥ c·∫•u tr√∫c).
    2.  **Truy v·∫•n song song (Parallel Retrieval)**: H·ªá th·ªëng ƒë·ªìng th·ªùi truy v·∫•n
        d·ªØ li·ªáu t·ª´ ChromaDB (d·ª±a tr√™n c√°c c√¢u h·ªèi con) v√† Neo4j (d·ª±a tr√™n c√°c
        th·ª±c th·ªÉ).
    3.  **TƒÉng c∆∞·ªùng t√≠n hi·ªáu ƒë·ªì th·ªã (Graph Signal Boosting)**: C√°c k·∫øt qu·∫£ t·ª´
        t√¨m ki·∫øm vector ƒë∆∞·ª£c "tƒÉng ƒëi·ªÉm" n·∫øu ch√∫ng ch·ª©a c√°c th·ª±c th·ªÉ ƒë∆∞·ª£c t√¨m th·∫•y
        ho·∫∑c c√≥ li√™n quan trong ƒë·ªì th·ªã tri th·ª©c.
    4.  **S·∫Øp x·∫øp l·∫°i (Reranking)**: M·ªôt m√¥ h√¨nh reranker ƒë∆∞·ª£c √°p d·ª•ng ƒë·ªÉ ƒë√°nh gi√°
        l·∫°i v√† s·∫Øp x·∫øp c√°c k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c k·∫øt h·ª£p v√† tƒÉng c∆∞·ªùng.
    5.  **T·ªïng h·ª£p c√¢u tr·∫£ l·ªùi (Response Synthesis)**: LLM cu·ªëi c√πng s·∫Ω t·ªïng h·ª£p
        c√¢u tr·∫£ l·ªùi m·∫°ch l·∫°c d·ª±a tr√™n nh·ªØng th√¥ng tin ƒë√£ ƒë∆∞·ª£c ch·ªçn l·ªçc v√† x·∫øp h·∫°ng.

Y√™u c·∫ßu th∆∞ vi·ªán:
    - llama-index-graph-stores-neo4j
    - llama-index-vector-stores-chroma
    - llama-index-embeddings-huggingface
    - llama-index-llms-openrouter
    - python-dotenv
    - sentence-transformers
    - chromadb
    - neo4j

C√†i ƒë·∫∑t:
    pip install llama-index-graph-stores-neo4j llama-index-vector-stores-chroma \\
                llama-index-embeddings-huggingface llama-index-llms-openrouter \\
                python-dotenv sentence-transformers

Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng:
    T·∫°o m·ªôt file `.env` trong c√πng th∆∞ m·ª•c v·ªõi script v√† ƒëi·ªÅn c√°c th√¥ng tin sau:
    OPENAI_API_KEY="sk-or-v1-..." (ƒê√¢y l√† key c·ªßa OpenRouter)
    YOUR_SITE_URL="http://localhost:8888"
    YOUR_SITE_NAME="VectorGraphRAG PoC"
    NEO4J_USERNAME="neo4j"
    NEO4J_PASSWORD="your_neo4j_password"
    NEO4J_URI="bolt://localhost:7687"

C√°ch ch·∫°y:
    python HybriRAG_v2_script.py
"""

import os
import re
import json
import logging
import asyncio
from typing import List, Optional, Dict, Any

import chromadb
from dotenv import load_dotenv

from llama_index.core import (
    Document,
    VectorStoreIndex,
    Settings,
    get_response_synthesizer,
    QueryBundle
)
from llama_index.core.schema import NodeWithScore
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.postprocessor import SentenceTransformerRerank
from llama_index.core.postprocessor.types import BaseNodePostprocessor
from llama_index.core.llms import ChatMessage
from llama_index.graph_stores.neo4j import Neo4jGraphStore
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.openrouter import OpenRouter


# --- C·∫§U H√åNH BAN ƒê·∫¶U ---

# Thi·∫øt l·∫≠p logging ƒë·ªÉ theo d√µi qu√° tr√¨nh ho·∫°t ƒë·ªông
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
load_dotenv()


def configure_global_settings():
    """
    C·∫•u h√¨nh c√°c thi·∫øt l·∫≠p to√†n c·ª•c cho LlamaIndex (LLM v√† model embedding).
    """
    Settings.llm = OpenRouter(
        api_key=os.getenv("OPENAI_API_KEY"),
        model="mistralai/mistral-7b-instruct:free",
        default_headers={
            "HTTP-Referer": os.getenv("YOUR_SITE_URL", "http://localhost:8888"),
            "X-Title": os.getenv("YOUR_SITE_NAME", "VectorGraphRAG PoC"),
        },
        max_tokens=512,
        temperature=0.1,
    )
    logging.info(f"‚úÖ LLM ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ s·ª≠ d·ª•ng model '{Settings.llm.model}' t·ª´ OpenRouter.")

    Settings.embed_model = HuggingFaceEmbedding(
        model_name="bkai-foundation-models/vietnamese-bi-encoder"
    )
    logging.info(f"‚úÖ Embedding model '{Settings.embed_model.model_name}' ƒë√£ ƒë∆∞·ª£c t·∫£i.")


def setup_datastores() -> tuple[Neo4jGraphStore, VectorStoreIndex]:
    """
    Kh·ªüi t·∫°o v√† n·∫°p d·ªØ li·ªáu v√†o Neo4j v√† ChromaDB.

    H√†m n√†y s·∫Ω x√≥a d·ªØ li·ªáu c≈© trong c·∫£ hai c∆° s·ªü d·ªØ li·ªáu tr∆∞·ªõc khi n·∫°p d·ªØ li·ªáu m·ªõi.
    ƒê√¢y l√† m·ªôt b∆∞·ªõc thi·∫øt l·∫≠p, th∆∞·ªùng ch·ªâ c·∫ßn ch·∫°y m·ªôt l·∫ßn.

    Returns:
        M·ªôt tuple ch·ª©a ƒë·ªëi t∆∞·ª£ng graph_store c·ªßa Neo4j v√† vector_index c·ªßa ChromaDB.
    """
    # --- D·ªØ li·ªáu m·∫´u ---
    text_docs = [
        Document(
            text="Tri·∫øt l√Ω thi·∫øt k·∫ø c·ªßa Steve Jobs t·∫°i Apple lu√¥n t·∫≠p trung v√†o s·ª± ƒë∆°n gi·∫£n, tr·ª±c quan v√† ƒë·∫∑t tr·∫£i nghi·ªám ng∆∞·ªùi d√πng l√†m trung t√¢m. √îng tin r·∫±ng s·∫£n ph·∫©m kh√¥ng ch·ªâ c·∫ßn m·∫°nh m·∫Ω v·ªÅ ch·ª©c nƒÉng m√† c√≤n ph·∫£i l√† m·ªôt t√°c ph·∫©m ngh·ªá thu·∫≠t, ƒë·∫πp t·ª´ trong ra ngo√†i. ƒêi·ªÅu n√†y ƒë√£ ƒë·ªãnh h√¨nh n√™n c√°c s·∫£n ph·∫©m bi·ªÉu t∆∞·ª£ng nh∆∞ iPhone v√† MacBook.",
            metadata={"source": "Ph√¢n t√≠ch n·ªôi b·ªô"}
        ),
        Document(
            text="iPhone 15, ra m·∫Øt nƒÉm 2023, ti·∫øp t·ª•c k·∫ø th·ª´a di s·∫£n thi·∫øt k·∫ø c·ªßa Apple v·ªõi khung vi·ªÅn titan, c·ªïng USB-C v√† h·ªá th·ªëng camera c·∫£i ti·∫øn m·∫°nh m·∫Ω. N√≥ ƒë∆∞·ª£c xem l√† m·ªôt trong nh·ªØng smartphone h√†ng ƒë·∫ßu th·ªã tr∆∞·ªùng, th·ªÉ hi·ªán r√µ tri·∫øt l√Ω c·ªßa c√¥ng ty.",
            metadata={"source": "ƒê√°nh gi√° s·∫£n ph·∫©m TechReview"}
        ),
        Document(
            text="Cu·ªôc ƒë·ªëi ƒë·∫ßu gi·ªØa Apple v√† Samsung l√† m·ªôt trong nh·ªØng c√¢u chuy·ªán kinh ƒëi·ªÉn c·ªßa l√†ng c√¥ng ngh·ªá. Trong khi Apple t·∫≠p trung v√†o h·ªá sinh th√°i kh√©p k√≠n v√† s·ª± t·ªëi ∆∞u h√≥a ph·∫ßn c·ª©ng-ph·∫ßn m·ªÅm, Samsung l·∫°i ƒëa d·∫°ng h√≥a s·∫£n ph·∫©m v·ªõi nhi·ªÅu ph√¢n kh√∫c v√† ti√™n phong trong c√°c c√¥ng ngh·ªá m√†n h√¨nh g·∫≠p.",
            metadata={"source": "B√†i b√°o kinh doanh"}
        ),
    ]
    graph_triplets = [
        ("Steve Jobs", "FOUNDED", "Apple"),
        ("Apple", "PRODUCES", "iPhone 15"),
        ("Apple", "HAS_PHILOSOPHY", "Thi·∫øt k·∫ø t·ªëi gi·∫£n v√† tr·∫£i nghi·ªám ng∆∞·ªùi d√πng"),
        ("Samsung", "PRODUCES", "Galaxy S24"),
        ("Samsung", "COMPETES_WITH", "Apple")
    ]

    # --- INGESTION V√ÄO NEO4J (GraphDB) ---
    logging.info("--- B·∫Øt ƒë·∫ßu Ingest v√†o Neo4j ---")
    graph_store = Neo4jGraphStore(
        username=os.getenv("NEO4J_USERNAME"),
        password=os.getenv("NEO4J_PASSWORD"),
        url=os.getenv("NEO4J_URI"),
        database="neo4j",
    )
    # X√≥a to√†n b·ªô d·ªØ li·ªáu c≈© ƒë·ªÉ ƒë·∫£m b·∫£o s·ª± s·∫°ch s·∫Ω
    graph_store.query("MATCH (n) DETACH DELETE n")
    for subj, pred, obj in graph_triplets:
        graph_store.upsert_triplet(subj, pred, obj)
    logging.info("--- Ingest v√†o Neo4j Ho√†n t·∫•t ---")

    # --- INGESTION V√ÄO CHROMADB (VectorDB) ---
    logging.info("--- B·∫Øt ƒë·∫ßu Ingest v√†o ChromaDB ---")
    db = chromadb.PersistentClient(path="./chroma_db")
    # X√≥a collection c≈© n·∫øu t·ªìn t·∫°i
    try:
        db.delete_collection("vector_graph_rag_poc")
        logging.info("Collection 'vector_graph_rag_poc' c≈© ƒë√£ ƒë∆∞·ª£c x√≥a.")
    except ValueError:
        logging.info("Kh√¥ng t√¨m th·∫•y collection c≈© ƒë·ªÉ x√≥a, s·∫Ω t·∫°o m·ªõi.")
        
    chroma_collection = db.get_or_create_collection("vector_graph_rag_poc")
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    vector_index = VectorStoreIndex.from_documents(
        text_docs, vector_store=vector_store
    )
    logging.info("--- Ingest v√†o ChromaDB Ho√†n t·∫•t ---")

    return graph_store, vector_index


# --- C√ÅC TH√ÄNH PH·∫¶N C·ª¶A PIPELINE RAG ---

def transform_query(query: str) -> dict:
    """
    S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n r√£ c√¢u h·ªèi ph·ª©c t·∫°p th√†nh c√°c th√†nh ph·∫ßn con.

    H√†m n√†y g·ª≠i c√¢u h·ªèi g·ªëc ƒë·∫øn LLM v·ªõi m·ªôt prompt ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát ƒë·ªÉ
    y√™u c·∫ßu LLM tr·∫£ v·ªÅ m·ªôt c·∫•u tr√∫c JSON. C·∫•u tr√∫c n√†y bao g·ªìm:
    - 'vector_search_queries': Danh s√°ch c√°c c√¢u h·ªèi con, ƒë·∫ßy ƒë·ªß ng·ªØ nghƒ©a,
      ph√π h·ª£p ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin m√¥ t·∫£ trong c∆° s·ªü d·ªØ li·ªáu vector.
    - 'graph_entities': Danh s√°ch c√°c th·ª±c th·ªÉ (danh t·ª´ ri√™ng, kh√°i ni·ªám) ch√≠nh
      c√≥ trong c√¢u h·ªèi, d√πng ƒë·ªÉ truy v·∫•n c√°c m·ªëi quan h·ªá trong ƒë·ªì th·ªã tri th·ª©c.

    Args:
        query: C√¢u h·ªèi g·ªëc t·ª´ ng∆∞·ªùi d√πng.

    Returns:
        M·ªôt dictionary ch·ª©a 'vector_search_queries' v√† 'graph_entities'.
        N·∫øu LLM tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá, h√†m s·∫Ω fallback b·∫±ng c√°ch s·ª≠ d·ª•ng
        c√¢u h·ªèi g·ªëc l√†m truy v·∫•n vector duy nh·∫•t v√† danh s√°ch th·ª±c th·ªÉ r·ªóng.
    """
    prompt = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch, chuy√™n ph√¢n t√≠ch v√† ph√¢n r√£ c√°c c√¢u h·ªèi ph·ª©c t·∫°p c·ªßa ng∆∞·ªùi d√πng th√†nh c√°c nhi·ªám v·ª• con cho m·ªôt h·ªá th·ªëng RAG. M·ª•c ti√™u c·ªßa b·∫°n l√† t√°ch c√¢u h·ªèi g·ªëc th√†nh m·ªôt danh s√°ch c√°c c√¢u h·ªèi con ƒë·ªôc l·∫≠p v√† tr√≠ch xu·∫•t c√°c th·ª±c th·ªÉ ch√≠nh. M·ªôt s·ªë c√¢u h·ªèi con s·∫Ω ƒë∆∞·ª£c d√πng ƒë·ªÉ truy v·∫•n c∆° s·ªü d·ªØ li·ªáu vector (ƒë·ªÉ l·∫•y th√¥ng tin m√¥ t·∫£), v√† c√°c th·ª±c th·ªÉ s·∫Ω ƒë∆∞·ª£c d√πng ƒë·ªÉ truy v·∫•n ƒë·ªì th·ªã tri th·ª©c (ƒë·ªÉ l·∫•y d·ªØ li·ªáu th·ª±c t·∫ø v√† c√°c m·ªëi quan h·ªá).

D·ª±a tr√™n c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng, h√£y t·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng JSON ch·ª©a hai danh s√°ch: 'vector_search_queries' v√† 'graph_entities'.

- 'vector_search_queries': Ch·ª©a c√°c c√¢u h·ªèi m√¥ t·∫£, ƒë·∫ßy ƒë·ªß √Ω nghƒ©a.
- 'graph_entities': Ch·ª©a c√°c th·ª±c th·ªÉ ch√≠nh ƒë∆∞·ª£c x√°c ƒë·ªãnh trong c√¢u h·ªèi.

User Question: "{query}"

{{
  "vector_search_queries": [],
  "graph_entities": []
}}
"""
    response = Settings.llm.chat([ChatMessage(role="user", content=prompt)])
    content = response.message.content

    try:
        # C·ªë g·∫Øng tr√≠ch xu·∫•t JSON n·∫øu n√≥ n·∫±m trong kh·ªëi markdown code
        json_match = re.search(r"```json\n(.*?)\n```", content, re.S)
        json_str = json_match.group(1) if json_match else content
        
        result = json.loads(json_str)
        # ƒê·∫£m b·∫£o c√°c kh√≥a c·∫ßn thi·∫øt t·ªìn t·∫°i
        if 'vector_search_queries' not in result:
            result['vector_search_queries'] = []
        if 'graph_entities' not in result:
            result['graph_entities'] = []
            
        return result
    except (json.JSONDecodeError, TypeError, AttributeError) as e:
        logging.error(f"L·ªói khi ph√¢n t√≠ch JSON t·ª´ LLM: {e}")
        logging.error(f"N·ªôi dung nh·∫≠n ƒë∆∞·ª£c t·ª´ LLM: '{content}'")
        logging.info("S·ª≠ d·ª•ng fallback: tr·∫£ v·ªÅ c√¢u h·ªèi g·ªëc l√†m truy v·∫•n vector.")
        return {"vector_search_queries": [query], "graph_entities": []}


def get_connected_entities(graph_store: Neo4jGraphStore, entity: str) -> List[str]:
    """
    Truy v·∫•n Neo4j ƒë·ªÉ t√¨m c√°c th·ª±c th·ªÉ c√≥ k·∫øt n·ªëi tr·ª±c ti·∫øp v·ªõi m·ªôt th·ª±c th·ªÉ cho tr∆∞·ªõc.

    Args:
        graph_store: ƒê·ªëi t∆∞·ª£ng k·∫øt n·ªëi ƒë·∫øn Neo4j.
        entity: T√™n c·ªßa th·ª±c th·ªÉ c·∫ßn t√¨m c√°c m·ªëi quan h·ªá.

    Returns:
        M·ªôt danh s√°ch c√°c ID c·ªßa c√°c th·ª±c th·ªÉ ƒë∆∞·ª£c k·∫øt n·ªëi.
    """
    query = f"""
    MATCH (e1 {{id: "{entity}"}})-- (e2)
    RETURN e2.id
    """
    try:
        result = graph_store.query(query)
        return [item['e2.id'] for item in result] if result else []
    except Exception as e:
        logging.error(f"L·ªói khi truy v·∫•n get_connected_entities cho '{entity}': {e}")
        return []


class GraphSignalBooster(BaseNodePostprocessor):
    """
    M·ªôt b·ªô x·ª≠ l√Ω h·∫≠u k·ª≥ (Node Postprocessor) ƒë·ªÉ tƒÉng ƒëi·ªÉm cho c√°c node vƒÉn b·∫£n
    d·ª±a tr√™n t√≠n hi·ªáu t·ª´ ƒë·ªì th·ªã tri th·ª©c.

    L·ªõp n√†y ho·∫°t ƒë·ªông b·∫±ng c√°ch:
    1. Nh·∫≠n m·ªôt danh s√°ch c√°c th·ª±c th·ªÉ ch√≠nh t·ª´ c√¢u h·ªèi (`graph_entities`).
    2. M·ªü r·ªông danh s√°ch n√†y b·∫±ng c√°ch truy v·∫•n ƒë·ªì th·ªã ƒë·ªÉ t√¨m c√°c th·ª±c th·ªÉ
       li√™n quan tr·ª±c ti·∫øp (1-hop neighbors).
    3. Khi x·ª≠ l√Ω c√°c node vƒÉn b·∫£n ƒë∆∞·ª£c truy xu·∫•t t·ª´ VectorDB, n√≥ s·∫Ω ki·ªÉm tra
       xem vƒÉn b·∫£n c·ªßa node c√≥ ch·ª©a b·∫•t k·ª≥ th·ª±c th·ªÉ n√†o trong danh s√°ch
       m·ªü r·ªông kh√¥ng.
    4. N·∫øu c√≥, ƒëi·ªÉm (score) c·ªßa node ƒë√≥ s·∫Ω ƒë∆∞·ª£c nh√¢n v·ªõi m·ªôt h·ªá s·ªë (`weight`),
       gi√∫p "ƒë·∫©y" c√°c node c√≥ li√™n quan ƒë·∫øn ƒë·ªì th·ªã l√™n v·ªã tr√≠ cao h∆°n trong
       danh s√°ch k·∫øt qu·∫£ cu·ªëi c√πng.
    
    Attributes:
        graph_entities (List[str]): Danh s√°ch c√°c th·ª±c th·ªÉ ban ƒë·∫ßu t·ª´ c√¢u h·ªèi.
        weight (float): H·ªá s·ªë ƒë·ªÉ tƒÉng ƒëi·ªÉm cho c√°c node ph√π h·ª£p.
    """
    graph_store: Neo4jGraphStore
    graph_entities: List[str] = []
    weight: float = 1.5
    _related_entities: set = set()

    def __init__(
        self,
        graph_store: Neo4jGraphStore,
        graph_entities: List[str],
        weight: float = 1.5,
        **kwargs: Any,
    ):
        """Kh·ªüi t·∫°o GraphSignalBooster."""
        super().__init__(
            graph_store=graph_store,
            graph_entities=graph_entities, 
            weight=weight, 
            **kwargs
        )
        self._related_entities = set(self.graph_entities)
        for entity in self.graph_entities:
            connected = get_connected_entities(self.graph_store, entity)
            self._related_entities.update(connected)
        logging.info(f"[GraphSignalBooster] C√°c th·ª±c th·ªÉ li√™n quan t·ª´ ƒë·ªì th·ªã: {self._related_entities}")

    def _postprocess_nodes(
        self, nodes: List[NodeWithScore], query_bundle: Optional[QueryBundle] = None
    ) -> List[NodeWithScore]:
        """TƒÉng ƒëi·ªÉm cho c√°c node ch·ª©a th·ª±c th·ªÉ li√™n quan."""
        boosted_nodes = []
        for node_with_score in nodes:
            node_text = node_with_score.node.get_content().lower()
            boost_factor = 1.0
            found_entities = []
            
            for entity in self._related_entities:
                # T√¨m ki·∫øm th·ª±c th·ªÉ d∆∞·ªõi d·∫°ng m·ªôt t·ª´ ho√†n ch·ªânh
                if re.search(r'\b' + re.escape(entity.lower()) + r'\b', node_text):
                    boost_factor = self.weight
                    found_entities.append(entity)
            
            if boost_factor > 1.0:
                logging.info(
                    f"[GraphSignalBooster] TƒÉng ƒëi·ªÉm cho node (source: "
                    f"{node_with_score.node.metadata.get('source')}) v√¨ ch·ª©a "
                    f"c√°c th·ª±c th·ªÉ li√™n quan: {found_entities}"
                )
                node_with_score.score *= boost_factor

            boosted_nodes.append(node_with_score)
        
        # S·∫Øp x·∫øp l·∫°i danh s√°ch node sau khi ƒë√£ tƒÉng ƒëi·ªÉm
        boosted_nodes.sort(key=lambda x: x.score, reverse=True)
        return boosted_nodes


async def retrieve_from_vector_db(retriever: VectorIndexRetriever, queries: List[str]) -> List[NodeWithScore]:
    """
    Th·ª±c hi·ªán truy v·∫•n b·∫•t ƒë·ªìng b·ªô ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu vector v·ªõi nhi·ªÅu c√¢u h·ªèi.

    Args:
        retriever: ƒê·ªëi t∆∞·ª£ng retriever c·ªßa VectorStoreIndex.
        queries: Danh s√°ch c√°c c√¢u h·ªèi con ƒë·ªÉ truy v·∫•n.

    Returns:
        M·ªôt danh s√°ch ph·∫≥ng ch·ª©a t·∫•t c·∫£ c√°c NodeWithScore ƒë∆∞·ª£c t√¨m th·∫•y.
    """
    tasks = [retriever.aretrieve(q) for q in queries]
    nested_results = await asyncio.gather(*tasks)
    
    all_nodes = []
    # Lo·∫°i b·ªè c√°c node tr√πng l·∫∑p d·ª±a tr√™n ID
    seen_node_ids = set()
    for result_list in nested_results:
        for node in result_list:
            if node.node.node_id not in seen_node_ids:
                all_nodes.append(node)
                seen_node_ids.add(node.node.node_id)

    logging.info(f"T·ªïng c·ªông truy xu·∫•t ƒë∆∞·ª£c {len(all_nodes)} node duy nh·∫•t t·ª´ VectorDB.")
    return all_nodes


async def retrieve_from_graph_db(graph_store: Neo4jGraphStore, entities: List[str]) -> List[Document]:
    """
    Th·ª±c hi·ªán truy v·∫•n b·∫•t ƒë·ªìng b·ªô ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu ƒë·ªì th·ªã cho m·ªôt danh s√°ch c√°c th·ª±c th·ªÉ.

    Args:
        graph_store: ƒê·ªëi t∆∞·ª£ng k·∫øt n·ªëi ƒë·∫øn Neo4j.
        entities: Danh s√°ch c√°c th·ª±c th·ªÉ ƒë·ªÉ truy v·∫•n.

    Returns:
        M·ªôt danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng Document, m·ªói Document ch·ª©a th√¥ng tin
        v·ªÅ c√°c m·ªëi quan h·ªá c·ªßa m·ªôt th·ª±c th·ªÉ.
    """
    async def query_entity(entity):
        # S·ª≠a c√¢u truy v·∫•n ƒë·ªÉ l·∫•y c·∫£ 3 th√†nh ph·∫ßn c·ªßa triplet
        cypher_query = f"MATCH (n {{id: '{entity}'}})-[r]-(m) RETURN n.id, type(r) as rel_type, m.id"
        try:
            # Ch·∫°y truy v·∫•n blocking trong m·ªôt aio thread ƒë·ªÉ kh√¥ng ch·∫∑n event loop
            graph_results = await asyncio.to_thread(graph_store.query, cypher_query)
            
            if graph_results:
                logging.info(f"  > K·∫øt qu·∫£ t·ª´ GraphDB cho '{entity}': ƒê√£ t√¨m th·∫•y {len(graph_results)} m·ªëi quan h·ªá.")
                # S·ª≠a c√°ch truy c·∫≠p k·∫øt qu·∫£ cho ph√π h·ª£p v·ªõi c√¢u query m·ªõi
                text_result = f"Th√¥ng tin t·ª´ ƒë·ªì th·ªã v·ªÅ '{entity}':\n" + "\n".join(
                    [f"- {res['n.id']} {res['rel_type']} {res['m.id']}" for res in graph_results]
                )
                return Document(text=text_result, metadata={"source": "GraphDB"})
            return None
        except Exception as e:
            logging.error(f"  > L·ªói khi truy v·∫•n GraphDB cho '{entity}': {e}")
            return None

    tasks = [query_entity(entity) for entity in entities]
    results = await asyncio.gather(*tasks)
    # L·ªçc ra nh·ªØng k·∫øt qu·∫£ kh√¥ng ph·∫£i None
    return [doc for doc in results if doc is not None]


async def run_hybrid_rag_pipeline(
    user_query: str, 
    graph_store: Neo4jGraphStore, 
    vector_index: VectorStoreIndex
):
    """
    Th·ª±c thi to√†n b·ªô pipeline RAG lai gh√©p.

    Args:
        user_query: C√¢u h·ªèi ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng.
        graph_store: ƒê·ªëi t∆∞·ª£ng graph_store ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.
        vector_index: ƒê·ªëi t∆∞·ª£ng vector_index ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.
    """
    print("\n" + "="*50)
    print(f"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω c√¢u h·ªèi: '{user_query}'")
    print("="*50 + "\n")

    # 1. Query Transformation
    print("--- B∆∞·ªõc 1: Ph√¢n r√£ c√¢u h·ªèi ---")
    transformed = transform_query(user_query)
    vector_queries = transformed.get('vector_search_queries', [user_query])
    graph_entities = transformed.get('graph_entities', [])
    print(f"  - Vector Queries: {vector_queries}")
    print(f"  - Graph Entities: {graph_entities}\n")
    
    # 2. Parallel Retrieval
    print("--- B∆∞·ªõc 2: Truy v·∫•n song song t·ª´ VectorDB v√† GraphDB ---")
    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=5)
    
    vector_task = retrieve_from_vector_db(vector_retriever, vector_queries)
    graph_task = retrieve_from_graph_db(graph_store, graph_entities)
    
    vector_retrieved_nodes, graph_retrieved_docs = await asyncio.gather(vector_task, graph_task)
    print("  - Truy v·∫•n song song ho√†n t·∫•t.\n")

    # 3. Combine and Rerank
    print("--- B∆∞·ªõc 3: K·∫øt h·ª£p, TƒÉng c∆∞·ªùng v√† S·∫Øp x·∫øp l·∫°i k·∫øt qu·∫£ ---")
    # K·∫øt h·ª£p k·∫øt qu·∫£ t·ª´ hai ngu·ªìn
    combined_nodes_and_docs = vector_retrieved_nodes + graph_retrieved_docs

    # Kh·ªüi t·∫°o c√°c b·ªô x·ª≠ l√Ω h·∫≠u k·ª≥
    graph_booster = GraphSignalBooster(
        graph_store=graph_store, 
        graph_entities=graph_entities, 
        weight=1.8 # TƒÉng tr·ªçng s·ªë ƒë·ªÉ t√≠n hi·ªáu ƒë·ªì th·ªã r√µ r√†ng h∆°n
    )
    reranker = SentenceTransformerRerank(
        model="BAAI/bge-reranker-v2-m3", 
        top_n=5 # Ch·ªâ gi·ªØ l·∫°i 5 k·∫øt qu·∫£ t·ªët nh·∫•t sau khi rerank
    )

    # √Åp d·ª•ng c√°c b·ªô x·ª≠ l√Ω
    # L∆∞u √Ω: LlamaIndex √°p d·ª•ng theo th·ª© t·ª± trong danh s√°ch
    # ·ªû ƒë√¢y ta s·∫Ω rerank tr∆∞·ªõc, sau ƒë√≥ m·ªõi boost t√≠n hi·ªáu t·ª´ graph
    # ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o c√°c t√†i li·ªáu li√™n quan nh·∫•t ƒë∆∞·ª£c ch·ªçn, sau ƒë√≥ ∆∞u ti√™n nh·ªØng c√°i c√≥ th·ª±c th·ªÉ ƒë·ªì th·ªã.
    reranked_nodes = reranker.postprocess_nodes(combined_nodes_and_docs, query_bundle=QueryBundle(user_query))
    logging.info(f"[Reranker] ƒê√£ gi·∫£m s·ªë l∆∞·ª£ng node xu·ªëng c√≤n {len(reranked_nodes)}.")
    
    final_nodes_for_synthesis = graph_booster.postprocess_nodes(reranked_nodes, query_bundle=QueryBundle(user_query))
    logging.info("[GraphSignalBooster] ƒê√£ √°p d·ª•ng tƒÉng c∆∞·ªùng t√≠n hi·ªáu ƒë·ªì th·ªã.")
    
    print("  - K·∫øt h·ª£p v√† x·ª≠ l√Ω h·∫≠u k·ª≥ ho√†n t·∫•t.\n")

    # 4. Response Synthesis
    print("--- B∆∞·ªõc 4: T·ªïng h·ª£p c√¢u tr·∫£ l·ªùi cu·ªëi c√πng ---")
    response_synthesizer = get_response_synthesizer(response_mode="compact")
    
    final_response = await response_synthesizer.asynthesize(
        query_bundle=QueryBundle(user_query),
        nodes=final_nodes_for_synthesis,
    )
    
    print("\n" + "="*50)
    print("‚úÖ C√¢u tr·∫£ l·ªùi cu·ªëi c√πng:")
    print("="*50)
    print(str(final_response))
    print("\n--- C√°c ngu·ªìn ƒë√£ s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi: ---")
    for node in final_response.source_nodes:
        source = node.metadata.get('source', 'N/A')
        content_preview = node.get_content().strip().replace('\n', ' ')[:150]
        print(f"- ƒêi·ªÉm: {node.score:.4f} | Ngu·ªìn: {source}")
        print(f"  N·ªôi dung: {content_preview}...")
    print("="*50 + "\n")


async def main():
    """
    H√†m ch√≠nh ƒë·ªÉ thi·∫øt l·∫≠p v√† ch·∫°y pipeline.
    """
    configure_global_settings()
    graph_store, vector_index = setup_datastores()
    
    # C√¢u h·ªèi v√≠ d·ª•
    complex_query = "Ph√¢n t√≠ch tri·∫øt l√Ω thi·∫øt k·∫ø c·ªßa Steve Jobs v√† n√≥ ·∫£nh h∆∞·ªüng ƒë·∫øn iPhone 15 nh∆∞ th·∫ø n√†o, m·ªôt s·∫£n ph·∫©m c·∫°nh tranh v·ªõi Samsung?"
    
    await run_hybrid_rag_pipeline(complex_query, graph_store, vector_index)


if __name__ == "__main__":
    # Ch·∫°y h√†m main b·∫•t ƒë·ªìng b·ªô
    asyncio.run(main())